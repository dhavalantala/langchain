{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain Intro\n",
    "\n",
    "- At its core, LangChain is a framework built around LLMs. I can use it for creating chatbots, summarization, Question Answering and many more. The core idea of the library is that I can “chain” together different components to create more advanced use cases around LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup \n",
    "\n",
    "- Installing langchain itself, it not enough. Using LangChain will usually require integrations with one or more model providers, data stores, apis, etc. \n",
    "\n",
    "- Let's use OpenAi for this demo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Large Language Models (LLMs)\n",
    "\n",
    "- Now that I have installed LangChain and set up my environment, I can start building my langugae model application. \n",
    "- The most basic building block of LangChain is calling an LLM on some intput. Let's walk through  a simple example of how to do this. For this purpose , let's pretend we are building a service that generates a company name based on what the company makes. \n",
    "- In oders to do this, we first need to import the LLM wrapper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Spice of India\" or \"Taste of India\"\n"
     ]
    }
   ],
   "source": [
    "query = \"What would be a good restaurant name fro a restaurent that makes indian coisine in germany?\"\n",
    "print(llm(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
